{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUht68DN9_FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#uploading file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A03Zpsw-AQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive       #mouting google drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDucAE7C-BV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykKiqq7g-Df1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQRASX7_-FEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading file\n",
        "f = open(\"stemming-assignment.txt\", \"r\")\n",
        "print(f.read()) \n",
        "data=list(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpjTYbac-HJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#making file to list\n",
        "li= [line.rstrip('\\n') for line in open(\"stemming-assignment.txt\")]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-9w7UEU-Iyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(li)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XxT9oMj-Kgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "li[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2D7_SCp-MJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "cwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RGdCbiJBjnN",
        "colab_type": "text"
      },
      "source": [
        "# Finding Cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOziQ6dH-Nuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating distance by formula\n",
        "arr = [[0]*23531 for _ in range(23531)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRPXcu6N-OXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(li)):                        #finding distance\n",
        "  if(i%1000==0):\n",
        "    print(i)\n",
        "  for j in range(len(li)):\n",
        "    distance=0\n",
        "    d1=list(li[i])\n",
        "    d2=list(li[j])\n",
        "    x=0\n",
        "    y=0\n",
        "    max_dis=max(len(d1),len(d2))\n",
        "    while x!=len(d1) and y!=len(d2):\n",
        "      if(d1[x]==d2[y]):\n",
        "        distance+=1\n",
        "        x+=1\n",
        "        y+=1\n",
        "      else:\n",
        "        break\n",
        "    arr[i][j]=distance/max_dis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFaWNpSR-Q1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np              #save arr  \n",
        "np.save('project_arr.npy', arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t36rPrj5-RgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import load            #load arr\n",
        "arr=load('/content/gdrive/My Drive/project_arr.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuyAwhGD-S-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_word=[]                 #making cluster\n",
        "for i in range(len(li)):\n",
        "  temp=[]\n",
        "  for j in range(len(li)):\n",
        "    if(arr[i][j]>0.6):\n",
        "      temp.append(li[j])\n",
        "  cluster_word.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaU8PCFZ-VGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fin_cul=[]                      #removing duplicate\n",
        "for i in range(len(cluster_word)):\n",
        "  cluster_word[i].sort()\n",
        "  if cluster_word[i] not in fin_cul:\n",
        "    fin_cul.append(cluster_word[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CodMvQin-Vda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fin_cul[:50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l97g4YWb-YjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def commonPrefixUtil(str1, str2):          #function to find common prefix\n",
        "\tn1 = len(str1) \n",
        "\tn2 = len(str2) \n",
        "\t\n",
        "\tresult = \"\"  \n",
        "\tj = 0\n",
        "\ti = 0\n",
        "\twhile(i <= n1 - 1 and j <= n2 - 1): \n",
        "\t\tif (str1[i] != str2[j]): \n",
        "\t\t\tbreak\n",
        "\t\tresult += (str1[i]) \n",
        "\t\t\n",
        "\t\ti += 1\n",
        "\t\tj += 1\n",
        "\n",
        "\treturn (result)  \n",
        "def commonPrefix(arr, n):  \n",
        "\tarr.sort(reverse = False) \n",
        "\treturn commonPrefixUtil(arr[0], arr[n - 1])  \n",
        "\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C0bJL8s-ZIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lp=[]                      #store common prefix\n",
        "for i in range(len(fin_cul)):\n",
        "  arr = fin_cul[i]\n",
        "  n = len(arr) \n",
        "  lp.append(commonPrefix(arr, n)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVfPpFQJ-ZOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(lp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFVYt1Z7-dgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_suffix=[]             #find temp suffix\n",
        "for i in range(len(fin_cul)):\n",
        "  temp=[]\n",
        "  n=len(lp[i])\n",
        "  for j in range(len(fin_cul[i])):\n",
        "    if(n==len(fin_cul[i][j])):\n",
        "      temp.append(\"\")\n",
        "    else:\n",
        "      temp.append(fin_cul[i][j][n:])\n",
        "  temp_suffix.append(temp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2gn-usH-frZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(temp_suffix[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2hb_AUG-fvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_word=0\n",
        "for i in range(len(lp)):\n",
        "    max_len_word=max(max_len_word,len(lp[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIL5-bBx-kcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_word          #max length of word "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTT6OUxU-k3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_suffix         #max length of suffix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2tyZJrX-5eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import patoolib          #exctrating files\n",
        "patoolib.extract_archive(\"TELEGRAPH_UTF8.rar\", outdir='/content/gdrive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJzRjLI1-61k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iT4WfgY-8lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHKj4LL2BTV4",
        "colab_type": "text"
      },
      "source": [
        "#Train/Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-C4JS5z-_Wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hps2(x):\n",
        "  fin2=[]\n",
        "  ans=0\n",
        "  if(len(x)<3):\n",
        "    return x\n",
        "  for i in range(0,10):\n",
        "    t1=0\n",
        "    t2=0\n",
        "    if i>len(x):\n",
        "      break\n",
        "    if i==0:\n",
        "      suff=''\n",
        "    else:\n",
        "      suff=x[-i:]\n",
        "    for j in range(len(temp_suffix)):\n",
        "      for k in range(len(temp_suffix[j])):\n",
        "        if(temp_suffix[j][k]==suff):\n",
        "          t1+=1\n",
        "    for j in range(len(fin_cul)):\n",
        "      for k in range(len(fin_cul[j])):\n",
        "        if i==0:\n",
        "          continue\n",
        "        if(len(fin_cul[j][k])<i):\n",
        "          continue\n",
        "        if(fin_cul[j][k][-i:]==suff):\n",
        "          #print(fin_cul[j][k])\n",
        "          t2+=1\n",
        "    if(t2!=0):\n",
        "      fin2.append(t1/t2)\n",
        "    else:\n",
        "      fin2.append(0.0)\n",
        "  m=0\n",
        "  for h in range(len(fin2)):\n",
        "    if(fin2[h]>m):\n",
        "      ans=h\n",
        "      m=fin2[h]\n",
        "    #print(fin2[h])\n",
        "  L=len(x)-ans\n",
        "  return x[0:L]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nto3Aip_BCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hps2('lips')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCoPfuQIBLvL",
        "colab_type": "text"
      },
      "source": [
        "#Pre processing of docs file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtTX_Na4_EQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re                          #function of contradiction\n",
        "contractions_dict = {\n",
        "'didn\\'t': 'did not',\n",
        "'don\\'t': 'do not',\n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}\n",
        "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "def expand_contractions(s, contractions_dict=contractions_dict):  #contraction function\n",
        "    def replace(match):                                              \n",
        "         return contractions_dict[match.group(0)]\n",
        "    return contractions_re.sub(replace, s)                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mbeRwKY_Ete",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer                    #porter stemmer import\n",
        "from nltk.tokenize import word_tokenize                #assign to ps\n",
        "ps = PorterStemmer()\n",
        "import pandas as pd                                    #import pandas\n",
        "import os                                              #import operating system library\n",
        "import xml.etree.ElementTree as ET                     #import XML tree library\n",
        "import re                                              #import regex\n",
        "from nltk.stem.wordnet import WordNetLemmatizer        #import wordnet for lematiation\n",
        "from xml.etree.ElementTree import tostring             #to convert into llist\n",
        "from nltk.corpus import stopwords                      #importing corpus for stopwords\n",
        "lmtzr=WordNetLemmatizer()                              #calling lemma function\n",
        "new_titles=[]                                          #empty list\n",
        "dataframe=[]                                           #storing final list after preprocessing\n",
        "filename=[]\n",
        "c=0\n",
        "stop_words = stopwords.words('english')                #english stop word    \n",
        "location = \"/content/gdrive/My Drive/TELEGRAPH_UTF8\"   #cahning the dir\n",
        "for r, d, f in os.walk(location):                      #reading all files in dir\n",
        "    for item in f:\n",
        "        if'.utf8' in item:\n",
        "            #try:\n",
        "              tree = ET.parse(os.path.join(r, item))              #parsing file with in tree \n",
        "              root = tree.getroot()                               #finding root\n",
        "              filename.append(root[0].text)\n",
        "              t = str(tostring(root))                             #converting into the string     \n",
        "              t=t.replace('\\\\n',' ')                              #replacing slash n with space\n",
        "              t=re.sub(' +', ' ', t)                              #print(t)#adujsting space with regex\n",
        "              titles = re.findall('<TEXT>(.*)</TEXT>',t)          #finding all the text betwwen TEXT tag\n",
        "              titles=str(titles)                                  #convert into string   \n",
        "              titles= re.sub(r'[^\\w\\s]','',titles)                #remove puncation\n",
        "              new_titles=titles.split(\" \")                        #making it into list\n",
        "              new_titles=[item.lower() for item in new_titles]    #conver into lower case\n",
        "              new_titles=[word for word in new_titles if word not in stop_words]#remove stop word\n",
        "              new_titles=map(expand_contractions,new_titles)      #remove contraction\n",
        "              temp=[]\n",
        "              for x in new_titles:\n",
        "                  if(x==ps.stem(x)):\n",
        "                      temp.append(x)\n",
        "                  else:\n",
        "                    try:\n",
        "                      temp.append(hps2(x))\n",
        "                    except:\n",
        "                      temp.append(x)\n",
        "              dataframe.append(str(temp))                   #making final list\n",
        "              print(c)\n",
        "              c+=1                                                #just to see that all dataframe working or not \n",
        "              if c%1000==0:\n",
        "                  print(c)\n",
        "            #except:\n",
        "                  #continue;                                                   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eZQjL6v_Gmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHxdGWXN_I6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(dataframe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEdchrJ5B9tO",
        "colab_type": "text"
      },
      "source": [
        "#Tf-idf on docs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9p-GdBZ_NSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer   #importing tfidf from sklearn library\n",
        "v = TfidfVectorizer(use_idf=True)                                      #calling method\n",
        "x = v.fit_transform(dataframe)                                #fit the data and apply it on string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCNQetPy_OnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.shape                                   #printing shape of x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJDJwNVT_QRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=x.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPtBgQj3_R_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse.linalg import svds,eigs\n",
        "import numpy as np\n",
        "U, s, Vh = svds(x,k=350)                           #calculating svd as k=350"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmRRGI80_Tv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sa=np.diag(s)                                    #s is vector matrix making it squre with digonal\n",
        "sa=np.linalg.inv(sa)                             #taking invers of s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zRMQVmM_VWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "vh_tran=np.matrix.transpose(Vh)                 #taking transpose if v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyDLdtaICA1D",
        "colab_type": "text"
      },
      "source": [
        "#Preporcessing of query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHFzlFH3_XCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd                                    #import pandas\n",
        "import os                                              #import operating system library\n",
        "import lxml.etree as ET                                #import XML tree library\n",
        "import re                                              #import regex\n",
        "from nltk.stem.wordnet import WordNetLemmatizer        #import wordnet for lematiation\n",
        "from xml.etree.ElementTree import tostring             #to convert into llist\n",
        "from nltk.corpus import stopwords                      #importing corpus for stopwords\n",
        "lmtzr=WordNetLemmatizer()                              #calling lemma function\n",
        "new_titles=[]                                          #temp empty list\n",
        "dataframe_new=[]                                       #final list for query matrix\n",
        "doc=[]\n",
        "stop_words = stopwords.words('english')                #english stop word    \n",
        "tree = ET.parse('en.topics.76-125.2010.txt')           #parsing file with in tree \n",
        "root = tree.getroot() \n",
        "t = str(tostring(root))                                #same preprocess as above\n",
        "t=t.replace('\\\\n',' ') \n",
        "t=re.sub(' +', ' ', t) \n",
        "for i in root.findall('top'):\n",
        "    titles = i.find('desc').text\n",
        "    t=list(filter(lambda a: a not in ['*','/','+','-','.','?',',','\\n',':',';','!','(',')'], list(titles)))\n",
        "    sw = stopwords.words(\"english\")\n",
        "    s=\"\".join(t).lower()\n",
        "    d=[]\n",
        "    for j in s.split():\n",
        "        if j not in sw:\n",
        "            d.append(j)\n",
        "    dataframe_new.append(\" \".join(d))\n",
        "    doc.append(i.find('num').text)\n",
        "                                                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryeq8ATU_Ynl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(dataframe_new)):\n",
        "  dataframe_new[i]=dataframe_new[i].split(\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5HIXq6N_dZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data=[]\n",
        "for i in range(len(dataframe_new)):\n",
        "  temp=[]\n",
        "  for j in range(len(dataframe_new[i])):\n",
        "    if(dataframe_new[i][j]==ps.stem(dataframe_new[i][j])):\n",
        "      temp.append(dataframe_new[i][j])\n",
        "    else:\n",
        "      try:\n",
        "        temp.append(hps2(dataframe_new[i][j]))\n",
        "      except:\n",
        "        temp.append(dataframe_new[i][j])\n",
        "  new_data.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpTEo2hi_jMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "que=[]\n",
        "for i in range(0,50):\n",
        "  listToStr=[]\n",
        "  listToStr = ' '.join([str(elem) for elem in new_data[i]])\n",
        "  que.append(listToStr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceWRlTTACNCs",
        "colab_type": "text"
      },
      "source": [
        "# tf-idf on query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg10Zgas_l1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1=v.transform(que)\n",
        "features=v.get_feature_names()                             #getting features name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfDnE_7p_eDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1=x1.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQVAo34h-8pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "temp=np.matmul(x1,U)\n",
        "X=np.matmul(temp,sa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsjUVnPMCYsN",
        "colab_type": "text"
      },
      "source": [
        "# Finding cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NA4Ki-X-ZMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity   #finding cosine similarity between query exapnsion and doc vector\n",
        "dictf={}\n",
        "x=[x for x in range(76,126)]\n",
        "for i in range(0,50):\n",
        "  temp=[]\n",
        "  for j in range(0,125581):\n",
        "    st=cosine_similarity(X[i].reshape(1,350),vh_tran[j].reshape(1,350))\n",
        "    temp.append(st)\n",
        "  key=x[i]\n",
        "  print(key)\n",
        "  dictf.update({key : temp})\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZUnmQiX_trL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame.from_dict(dictf,orient='index',columns=filename)  #making dataframe with query id map it to our document"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvZEAVuB_uQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_queries={}                                     #top 10 docs via sorting\n",
        "indexlist=df.index.values.tolist()\n",
        "for index in indexlist:\n",
        "  sorted_val=df.loc[index,:].sort_values(ascending=False).index.values.tolist()\n",
        "  value=','.join(sorted_val[0:10])\n",
        "  final_queries.update({index:str(value)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0CInXOE_v1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keepitsafe={}                        #making it list of dict\n",
        "for i,v in final_queries.items():\n",
        "  l1=[]\n",
        "  l2=[] \n",
        "  l1.append(i) \n",
        "  l2 = list(v.split(\",\"))\n",
        "  keepitsafe.update({l1[0]:l2 })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUH3IJIe_xVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"qr.txt\") as file:   #finding rel docs with doc number of given file\n",
        "    \n",
        "    n=76\n",
        "    rele={}\n",
        "    rl=[]\n",
        "    count=0\n",
        "    for i in file:\n",
        "        t=i.split()\n",
        "        if int(t[0])==n:\n",
        "            if int(t[-1])==1:\n",
        "                count+=1\n",
        "                rl.append(t[-2])\n",
        "        else:\n",
        "            rele[n]=rl\n",
        "            rl=[]\n",
        "            n+=1\n",
        "            if int(t[-1])==1:\n",
        "                count+=1\n",
        "                rl.append(t[-2])\n",
        "    rele[n]=rl\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WygZ-VeZ_y0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "countit={}                          #actual matched documets query wise\n",
        "dict_fin={}\n",
        "temp=76\n",
        "c_r=0\n",
        "print(\"ID : and its relevent docs we have found and true\")\n",
        "for i,v in rele.items():\n",
        "  for i1,v1 in keepitsafe.items():\n",
        "    if(i==i1):\n",
        "      l1=[]\n",
        "      j=str(i)\n",
        "      l1=[value for value in v1 if value in v]\n",
        "      c_r+=len(l1)\n",
        "      x=' '.join([str(elem) for elem in l1])\n",
        "      dict_fin[temp]=l1\n",
        "      temp+=1\n",
        "      print(j+'  '+x)\n",
        "      countit.update({i:len(l1)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrMN6rqWCdE1",
        "colab_type": "text"
      },
      "source": [
        "# Finding scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz9EJo_v_0l0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_r                #no of rel docs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYHmBTeM_9qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=c_r/653          #recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KjS-xBqAC0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv04-JneAAW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=c_r/500         #precsion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvkMb3BPAF0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5sG2fXNAA4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1=2*(x*y/(x+y))       #f1 score"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}