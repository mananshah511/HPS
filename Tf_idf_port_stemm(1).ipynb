{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tf-idf/port_stemm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMOxM6K_61TA",
        "colab_type": "code",
        "outputId": "4efb7525-9562-4fcf-87d6-20e246785905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive       #mouting google drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh3nF8ie7qQs",
        "colab_type": "code",
        "outputId": "43a2b34d-c2b3-466c-cb73-1b7adf2fdc6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pip install patool"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: patool in /usr/local/lib/python3.6/dist-packages (1.12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2RqR63A8N3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os          #importing os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb_TItp68M4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive')      #changing curr dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTkPwcL47-NB",
        "colab_type": "code",
        "outputId": "4c729592-a393-4661-f423-8caa6d43519c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "import patoolib          #exctrating files\n",
        "patoolib.extract_archive(\"TELEGRAPH_UTF8.rar\", outdir='/content/gdrive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "patool: Extracting TELEGRAPH_UTF8.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/gdrive/My Drive/TELEGRAPH_UTF8.rar\"\n",
            "patool:     with cwd='/content/gdrive/My Drive'\n",
            "patool: ... TELEGRAPH_UTF8.rar extracted to `/content/gdrive/My Drive'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2ugUEFhn17k",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing on docs data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7RMWYcY8Buc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re                          #function of contradiction\n",
        "contractions_dict = {\n",
        "'didn\\'t': 'did not',\n",
        "'don\\'t': 'do not',\n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}\n",
        "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "def expand_contractions(s, contractions_dict=contractions_dict):  #contraction function\n",
        "    def replace(match):                                              \n",
        "         return contractions_dict[match.group(0)]\n",
        "    return contractions_re.sub(replace, s)                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuWwc2y8A1j9",
        "colab_type": "code",
        "outputId": "bdf25ee1-7028-4c42-b30a-0a776ca0eb54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzoEZSGRBKFc",
        "colab_type": "code",
        "outputId": "d31671ad-080f-49f9-8044-2173b03eb542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5itnrC8LBMlT",
        "colab_type": "code",
        "outputId": "a38af61d-255d-4a16-f2d4-2760f2655e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer                    #library for port stemmer\n",
        "from nltk.tokenize import word_tokenize \n",
        "ps = PorterStemmer()                                   #calling function to ps\n",
        "import pandas as pd                                    #import pandas\n",
        "import os                                              #import operating system library\n",
        "import xml.etree.ElementTree as ET                     #import XML tree library\n",
        "import re                                              #import regex\n",
        "from nltk.stem.wordnet import WordNetLemmatizer        #import wordnet for lematiation\n",
        "from xml.etree.ElementTree import tostring             #to convert into llist\n",
        "from nltk.corpus import stopwords                      #importing corpus for stopwords\n",
        "lmtzr=WordNetLemmatizer()                              #calling lemma function\n",
        "new_titles=[]                                          #empty list\n",
        "dataframe=[]                                           #storing final list after preprocessing\n",
        "filename=[]\n",
        "c=0\n",
        "stop_words = stopwords.words('english')                #english stop word    \n",
        "location = \"/content/gdrive/My Drive/TELEGRAPH_UTF8\"   #cahning the dir\n",
        "for r, d, f in os.walk(location):                      #reading all files in dir\n",
        "    for item in f:\n",
        "        if'.utf8' in item:\n",
        "            try:\n",
        "                tree = ET.parse(os.path.join(r, item))              #parsing file with in tree \n",
        "                root = tree.getroot()                               #finding root\n",
        "                filename.append(root[0].text)\n",
        "                t = str(tostring(root))                             #converting into the string     \n",
        "                t=t.replace('\\\\n',' ')                              #replacing slash n with space\n",
        "                t=re.sub(' +', ' ', t)                              #print(t)#adujsting space with regex\n",
        "                titles = re.findall('<TEXT>(.*)</TEXT>',t)          #finding all the text betwwen TEXT tag\n",
        "                titles=str(titles)                                  #convert into string   \n",
        "                titles= re.sub(r'[^\\w\\s]','',titles)                #remove puncation\n",
        "                new_titles=titles.split(\" \")                        #making it into list\n",
        "                new_titles=[item.lower() for item in new_titles]    #conver into lower case\n",
        "                new_titles=[word for word in new_titles if word not in stop_words]#remove stop word\n",
        "                new_titles=map(expand_contractions,new_titles)      #remove contraction\n",
        "                temp=[]\n",
        "                for x in new_titles:\n",
        "                    temp.append(ps.stem(x))                   #stemming \n",
        "                dataframe.append(str(temp))                   #making final list\n",
        "                #print(c)\n",
        "                c+=1                                                #just to see that all dataframe working or not \n",
        "                if c%1000==0:\n",
        "                    print(c)\n",
        "            except:\n",
        "                  continue;                                                   "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n",
            "74000\n",
            "75000\n",
            "76000\n",
            "77000\n",
            "78000\n",
            "79000\n",
            "80000\n",
            "81000\n",
            "82000\n",
            "83000\n",
            "84000\n",
            "85000\n",
            "86000\n",
            "87000\n",
            "88000\n",
            "89000\n",
            "90000\n",
            "91000\n",
            "92000\n",
            "93000\n",
            "94000\n",
            "95000\n",
            "96000\n",
            "97000\n",
            "98000\n",
            "99000\n",
            "100000\n",
            "101000\n",
            "102000\n",
            "103000\n",
            "104000\n",
            "105000\n",
            "106000\n",
            "107000\n",
            "108000\n",
            "109000\n",
            "110000\n",
            "111000\n",
            "112000\n",
            "113000\n",
            "114000\n",
            "115000\n",
            "116000\n",
            "117000\n",
            "118000\n",
            "119000\n",
            "120000\n",
            "121000\n",
            "122000\n",
            "123000\n",
            "124000\n",
            "125000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMBm2u6OBb9t",
        "colab_type": "code",
        "outputId": "dc5fd3c1-4c20-463d-9b81-2e6057278fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(dataframe)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9jTax-DFjVE",
        "colab_type": "code",
        "outputId": "bcc8e599-ce8b-4b52-945c-758d3d0a4e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(filename)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBPBmlnHaIqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b45958bd-690d-45d3-e63d-6cb4b815fe06"
      },
      "source": [
        "dataframe[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['', 'telegraph', '', 'calcutta', '', 'leisur', 'tuesday', 'decemb', '07', '2004', 'leonardo', 'dicaprio', 'one', 'moment', 'didnt', 'know', 'whether', 'laugh', 'cri', 'south', 'american', 'rainforest', 'studi', 'effect', 'mercuri', 'poison', 'amazon', 'confront', 'group', 'nake', 'ind', 'six', 'oscar', 'big', 'profit', 'chicago', 'spark', 'new', 'frenzi', 'film', 'music', 'andrew', 'lloyd', 'webber', '', 'coupl', 'live', 'togeth', 'britain', 'without', 'get', 'marri', 'warn', 'today', 'risk', 'lose', 'home', 'po', '', 'may', 'come', 'crunch', '', 'squelch', 'creator', 'hope', 'splash', '', 'french', 'fashion', 'legend', 'pierr', 'cardin', 'put', 'much', 'empir', 'sale', 'seek', '1', 'billion', 'coutur', 'licen', '', 'famili', 'astonishingli', 'even', 'today', 'mani', 'parent', 'believ', 'bring', 'daughter', 'secur', 'gild', 'cage', 'insul', 'first', 'cousin', '27', 'year', 'old', 'want', 'get', 'marri', 'parent', 'particularli', 'interest', 'friend', 'mine', 'actor', 'dian', 'kruger', 'uk', 'premier', 'film', 'nation', 'treasur', 'london', 'reuter', '']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T63V95W1n74Q",
        "colab_type": "text"
      },
      "source": [
        "# Tf-idf on docs Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQvXyg8vFk9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer   #importing tfidf from sklearn library\n",
        "v = TfidfVectorizer(use_idf=True)                                      #calling method\n",
        "x = v.fit_transform(dataframe)                                #fit the data and apply it on string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5Ylz1sIaV0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50f75a69-2271-4f63-8692-f5ce251e30cf"
      },
      "source": [
        "x.shape                                   #printing shape of x"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125581, 320223)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGi9-UR3ady6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=x.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bS_db7YaggR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse.linalg import svds,eigs\n",
        "import numpy as np\n",
        "U, s, Vh = svds(x,k=350)                           #calculating svd as k=350"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgBMZjG6ajTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sa=np.diag(s)                                    #s is vector matrix making it squre with digonal\n",
        "sa=np.linalg.inv(sa)                             #taking invers of s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WXJaTXLcYAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "vh_tran=np.matrix.transpose(Vh)                 #taking transpose if v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysVmarfvoBP3",
        "colab_type": "text"
      },
      "source": [
        "#Pre processing on Query files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNh0qYv_caMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd                                    #import pandas\n",
        "import os                                              #import operating system library\n",
        "import lxml.etree as ET                                #import XML tree library\n",
        "import re                                              #import regex\n",
        "from nltk.stem.wordnet import WordNetLemmatizer        #import wordnet for lematiation\n",
        "from xml.etree.ElementTree import tostring             #to convert into llist\n",
        "from nltk.corpus import stopwords                      #importing corpus for stopwords\n",
        "lmtzr=WordNetLemmatizer()                              #calling lemma function\n",
        "new_titles=[]                                          #temp empty list\n",
        "dataframe_new=[]                                       #final list for query matrix\n",
        "doc=[]\n",
        "stop_words = stopwords.words('english')                #english stop word    \n",
        "tree = ET.parse('en.topics.76-125.2010.txt')           #parsing file with in tree \n",
        "root = tree.getroot() \n",
        "t = str(tostring(root))                                #same preprocess as above\n",
        "t=t.replace('\\\\n',' ') \n",
        "t=re.sub(' +', ' ', t) \n",
        "for i in root.findall('top'):\n",
        "    titles = i.find('desc').text\n",
        "    t=list(filter(lambda a: a not in ['*','/','+','-','.','?',',','\\n',':',';','!','(',')'], list(titles)))\n",
        "    sw = stopwords.words(\"english\")\n",
        "    s=\"\".join(t).lower()\n",
        "    d=[]\n",
        "    for j in s.split():\n",
        "        if j not in sw:\n",
        "            d.append(j)\n",
        "    dataframe_new.append(\" \".join(d))\n",
        "    doc.append(i.find('num').text)\n",
        "                                                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "098M3dYFchMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68a3d3eb-2086-4822-e255-025619bf0185"
      },
      "source": [
        "len(dataframe_new)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J2Ftxahci0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(dataframe_new)):                #making tokens\n",
        "  dataframe_new[i]=dataframe_new[i].split(\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzX8alx_cllh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data=[]                                 #porter stemming to query files\n",
        "for i in range(len(dataframe_new)):\n",
        "  temp=[]\n",
        "  for j in range(len(dataframe_new[i])):\n",
        "    temp.append(ps.stem(dataframe_new[i][j]))\n",
        "  new_data.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvs_xAKPc5qc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "134d9ee5-947d-4c99-d841-790b0fabf801"
      },
      "source": [
        "new_data"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['reason',\n",
              "  'behind',\n",
              "  'protest',\n",
              "  'meena',\n",
              "  'leader',\n",
              "  'theinclus',\n",
              "  'gurjar',\n",
              "  'schedul',\n",
              "  'tribe'],\n",
              " ['attack', 'hezbollah', 'guerrilla', 'indian', 'isra', 'forc'],\n",
              " ['conflict',\n",
              "  'ashok',\n",
              "  'singhal',\n",
              "  'presid',\n",
              "  'vishwahindu',\n",
              "  'parishad',\n",
              "  'lk',\n",
              "  'advani',\n",
              "  'bjp',\n",
              "  'leader',\n",
              "  'rammandir',\n",
              "  'issu'],\n",
              " ['plan', 'build', 'road', 'china', 'mount', 'everest'],\n",
              " ['initi',\n",
              "  'legal',\n",
              "  'proceed',\n",
              "  'advani',\n",
              "  'hisinvolv',\n",
              "  'demolit',\n",
              "  'babri',\n",
              "  'masjid'],\n",
              " ['health',\n",
              "  'ministri',\n",
              "  'india',\n",
              "  'made',\n",
              "  'certain',\n",
              "  'plan',\n",
              "  'toprotect',\n",
              "  'indian',\n",
              "  'children',\n",
              "  'outbreak',\n",
              "  'japaneseenceph',\n",
              "  'problem',\n",
              "  'arisen',\n",
              "  'cours',\n",
              "  'ofimpl',\n",
              "  'plan'],\n",
              " ['propos',\n",
              "  'bu',\n",
              "  'servic',\n",
              "  'srinagar',\n",
              "  'muzaffarabadand',\n",
              "  'role',\n",
              "  'solv',\n",
              "  'indopak',\n",
              "  'disput'],\n",
              " ['attempt',\n",
              "  'made',\n",
              "  'laloo',\n",
              "  'prasad',\n",
              "  'yadav',\n",
              "  'ram',\n",
              "  'vila',\n",
              "  'paswan',\n",
              "  'togain',\n",
              "  'vote',\n",
              "  'muslim',\n",
              "  'voter'],\n",
              " ['alleg',\n",
              "  'rais',\n",
              "  'brinda',\n",
              "  'karat',\n",
              "  'medicin',\n",
              "  'sold',\n",
              "  'byswami',\n",
              "  'ramdev',\n",
              "  'contain',\n",
              "  'anim',\n",
              "  'part'],\n",
              " ['order',\n",
              "  'pass',\n",
              "  'court',\n",
              "  'remand',\n",
              "  'abu',\n",
              "  'salem',\n",
              "  'accus',\n",
              "  'inth',\n",
              "  'mumbai',\n",
              "  'bomb',\n",
              "  'blast',\n",
              "  'case',\n",
              "  'jail',\n",
              "  'custodi'],\n",
              " [\"government'\",\n",
              "  'decis',\n",
              "  'privat',\n",
              "  'mumbai',\n",
              "  'delhiairport',\n",
              "  'call',\n",
              "  'tender',\n",
              "  'bid',\n",
              "  'regard'],\n",
              " ['discuss',\n",
              "  'manmohan',\n",
              "  'singh',\n",
              "  'prime',\n",
              "  'minist',\n",
              "  'indiaand',\n",
              "  'pervez',\n",
              "  'musharraf',\n",
              "  'presid',\n",
              "  'pakistan',\n",
              "  'regard',\n",
              "  'theposit',\n",
              "  'troop',\n",
              "  'around',\n",
              "  'siachen'],\n",
              " ['arrest',\n",
              "  'jayendra',\n",
              "  'saraswati',\n",
              "  'shankaracharya',\n",
              "  'kanchi',\n",
              "  'andvijayendra',\n",
              "  'saraswati',\n",
              "  'alleg',\n",
              "  'involv',\n",
              "  'inth',\n",
              "  'murder',\n",
              "  'shankar',\n",
              "  'raman',\n",
              "  \"people'\",\n",
              "  'protest',\n",
              "  'againstthes',\n",
              "  'arrest'],\n",
              " ['alleg',\n",
              "  'involv',\n",
              "  'extern',\n",
              "  'affair',\n",
              "  'minist',\n",
              "  'natwarsingh',\n",
              "  'congress',\n",
              "  'minist',\n",
              "  'iraqi',\n",
              "  'oilforfoodscam',\n",
              "  'relat',\n",
              "  'investig'],\n",
              " ['visit',\n",
              "  'team',\n",
              "  'indian',\n",
              "  'repres',\n",
              "  'dhaka',\n",
              "  'todiscuss',\n",
              "  'issu',\n",
              "  'like',\n",
              "  'share',\n",
              "  'water',\n",
              "  'secur',\n",
              "  'trainingcamp',\n",
              "  'milit'],\n",
              " ['charg', 'financi', 'corrupt', 'pratibha', 'patil'],\n",
              " ['insurg', 'activ', 'tamil', 'tiger', 'sri', 'lanka'],\n",
              " ['member',\n",
              "  'indian',\n",
              "  'parliament',\n",
              "  'caught',\n",
              "  'camera',\n",
              "  'acceptingbrib',\n",
              "  'rais',\n",
              "  'question',\n",
              "  'parliament'],\n",
              " ['investig', 'accus', 'classifiedinform', 'leak', 'indian', 'navi'],\n",
              " ['racism',\n",
              "  'row',\n",
              "  'big',\n",
              "  'brother',\n",
              "  'show',\n",
              "  'involv',\n",
              "  'shilpashetti',\n",
              "  'jade',\n",
              "  'goodi'],\n",
              " ['statement',\n",
              "  'made',\n",
              "  'pramod',\n",
              "  \"mahajan'\",\n",
              "  'killer',\n",
              "  'court',\n",
              "  'denyingcharg'],\n",
              " ['feud',\n",
              "  'mukesh',\n",
              "  'ambani',\n",
              "  'anil',\n",
              "  'ambani',\n",
              "  'regard',\n",
              "  'ownership',\n",
              "  'thereli',\n",
              "  'group'],\n",
              " [\"india'\", 'dismiss', \"china'\", 'claim', 'arunach', 'pradesh'],\n",
              " ['evid', 'regard', 'laloo', 'prasad', \"yadav'\", 'involv', 'thefodd', 'scam'],\n",
              " ['monica', 'bedi', 'charg', 'obtain', 'forg', 'passport', 'athyderabad'],\n",
              " ['detail',\n",
              "  'drinkanddrug',\n",
              "  'parti',\n",
              "  'late',\n",
              "  \"pramodmahajan'\",\n",
              "  'offici',\n",
              "  'bungalow',\n",
              "  'rahul',\n",
              "  'son',\n",
              "  'bibekmoitra',\n",
              "  'possibl',\n",
              "  'other',\n",
              "  'involv'],\n",
              " ['charg', 'dope', 'shoaib', 'akhtar', 'mohammad', 'asif'],\n",
              " [\"india'\",\n",
              "  'posit',\n",
              "  'indopak',\n",
              "  'conflict',\n",
              "  'thebaglihar',\n",
              "  'hydroelectr',\n",
              "  'power',\n",
              "  'project'],\n",
              " ['legal',\n",
              "  'step',\n",
              "  'jaya',\n",
              "  'bachchan',\n",
              "  'taken',\n",
              "  'beingdisqualifi',\n",
              "  'rajya',\n",
              "  'sabha',\n",
              "  'membership',\n",
              "  'hold',\n",
              "  'anoffic',\n",
              "  'profit'],\n",
              " ['cbi',\n",
              "  'investig',\n",
              "  'alleg',\n",
              "  'involv',\n",
              "  'chiefminist',\n",
              "  'highli',\n",
              "  'place',\n",
              "  'bureaucrat',\n",
              "  'uttar',\n",
              "  'pradesh',\n",
              "  'inth',\n",
              "  'multicror',\n",
              "  'taj',\n",
              "  'heritag',\n",
              "  'corridor',\n",
              "  'scandal'],\n",
              " ['taslima',\n",
              "  \"nasreen'\",\n",
              "  'novel',\n",
              "  '\"shame\"',\n",
              "  'ban',\n",
              "  'hurt',\n",
              "  'muslimreligi',\n",
              "  'sentiment'],\n",
              " ['accus',\n",
              "  'bjp',\n",
              "  'publish',\n",
              "  'cd',\n",
              "  'containingantimuslim',\n",
              "  'materi',\n",
              "  'runup',\n",
              "  'elect',\n",
              "  'inuttar',\n",
              "  'pradesh',\n",
              "  'india',\n",
              "  'step',\n",
              "  'taken',\n",
              "  'bjp',\n",
              "  'thisregard'],\n",
              " ['demand',\n",
              "  'greater',\n",
              "  'nagaland',\n",
              "  'made',\n",
              "  'nscn',\n",
              "  'nagaorgan',\n",
              "  'protest',\n",
              "  'made',\n",
              "  'neighbour',\n",
              "  'statesagainst',\n",
              "  'demand'],\n",
              " ['raj',\n",
              "  \"thackeray'\",\n",
              "  'decis',\n",
              "  'form',\n",
              "  'new',\n",
              "  'polit',\n",
              "  'parti',\n",
              "  'inmumbai',\n",
              "  'announc',\n",
              "  'new',\n",
              "  'parti'],\n",
              " ['border', 'trade', 'nathu', 'la', 'impact', 'onsinoindian', 'relat'],\n",
              " ['ban', \"mumbai'\", 'danc', 'bar', 'protest', 'dancer', 'againstth', 'ban'],\n",
              " ['link',\n",
              "  'goa',\n",
              "  'manikchand',\n",
              "  'gutkha',\n",
              "  'manufacturingcompani',\n",
              "  'dawood',\n",
              "  'ibrahim'],\n",
              " ['clash', 'within', 'bnp', 'bnp', 'awamileagu', 'bangladesh'],\n",
              " ['arm',\n",
              "  'deal',\n",
              "  'sign',\n",
              "  'georg',\n",
              "  'fernandez',\n",
              "  'denel',\n",
              "  'demandsmad',\n",
              "  'pranab',\n",
              "  'mukherje',\n",
              "  'investig',\n",
              "  'intoirregular',\n",
              "  'deal'],\n",
              " ['casualti', 'result', 'serial', 'blast', 'sankatmochantempl'],\n",
              " ['step',\n",
              "  'acb',\n",
              "  'take',\n",
              "  'daya',\n",
              "  'nayak',\n",
              "  'thedisproportion',\n",
              "  'asset',\n",
              "  'da',\n",
              "  'case'],\n",
              " ['offer',\n",
              "  'talk',\n",
              "  'made',\n",
              "  'tribal',\n",
              "  \"orissagovernment'\",\n",
              "  'plea',\n",
              "  'central',\n",
              "  'mediat',\n",
              "  'connect',\n",
              "  'withth',\n",
              "  'controversi',\n",
              "  'land',\n",
              "  'acquisit',\n",
              "  'kalinganagar'],\n",
              " ['possibl',\n",
              "  'involv',\n",
              "  'pakistani',\n",
              "  'terrorist',\n",
              "  'group',\n",
              "  'behindth',\n",
              "  'ayodhya',\n",
              "  'attack',\n",
              "  'effect',\n",
              "  'attack'],\n",
              " ['controversi', 'taj', 'mahal', 'take'],\n",
              " ['charg',\n",
              "  'anara',\n",
              "  'gupta',\n",
              "  'erstwhil',\n",
              "  'miss',\n",
              "  'jammu',\n",
              "  'herinvolv',\n",
              "  'sex',\n",
              "  'cd',\n",
              "  'scandal',\n",
              "  'report',\n",
              "  'theandhra',\n",
              "  'pradesh',\n",
              "  'forens',\n",
              "  'laboratori',\n",
              "  'regard'],\n",
              " ['deadli', 'explos', 'samjhauta', 'express'],\n",
              " ['surrend',\n",
              "  'sanjay',\n",
              "  'dutt',\n",
              "  'actor',\n",
              "  'convict',\n",
              "  '1993mumbai',\n",
              "  'blast',\n",
              "  'case'],\n",
              " ['death', 'palestinian', 'leader', 'yasser', 'arafat'],\n",
              " ['trade', 'illeg', 'drug', 'variou', 'state', 'india'],\n",
              " ['sieg', 'lal', 'masjid', 'islamabad', 'fundamentalist', 'student']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hbs4Bpxc7hI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "que=[]                                           #making string\n",
        "for i in range(0,50):\n",
        "  listToStr=[]\n",
        "  listToStr = ' '.join([str(elem) for elem in new_data[i]])\n",
        "  que.append(listToStr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-3f9cnboFp-",
        "colab_type": "text"
      },
      "source": [
        "#Tf-idf on Query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Xy0TsTc_Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1=v.transform(que)\n",
        "features=v.get_feature_names()                             #getting features name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcGJp2gMdCZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1=x1.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rRtlTdJdELr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "temp=np.matmul(x1,U)\n",
        "X=np.matmul(temp,sa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgCgCs2SdF05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9dd0f85-e5a6-4ad3-abb5-8fa3f7fb9f8f"
      },
      "source": [
        "len(filename)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py4cqnLqdIt2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1dde512d-1ef2-4466-80c1-c027d0804bb4"
      },
      "source": [
        "len(dataframe)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HEdAKoRoKDg",
        "colab_type": "text"
      },
      "source": [
        "#Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9DwCRSkdKr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "7cb2fc5e-4661-49c8-9dee-a4b2d34fd636"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity   #finding cosine similarity between query exapnsion and doc vector\n",
        "dictf={}\n",
        "x=[x for x in range(76,126)]\n",
        "for i in range(0,50):\n",
        "  temp=[]\n",
        "  for j in range(0,125581):\n",
        "    st=cosine_similarity(X[i].reshape(1,350),vh_tran[j].reshape(1,350))\n",
        "    temp.append(st)\n",
        "  key=x[i]\n",
        "  print(key)\n",
        "  dictf.update({key : temp})"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz6m2mL3dMhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame.from_dict(dictf,orient='index',columns=filename)  #making dataframe with query id map it to our document"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeRvXg6ciS42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_queries={}                                     #top 10 docs via sorting\n",
        "indexlist=df.index.values.tolist()\n",
        "for index in indexlist:\n",
        "  sorted_val=df.loc[index,:].sort_values(ascending=False).index.values.tolist()\n",
        "  value=','.join(sorted_val[0:10])\n",
        "  final_queries.update({index:str(value)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRIaU8z0iXTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keepitsafe={}                        #making it list of dict\n",
        "for i,v in final_queries.items():\n",
        "  l1=[]\n",
        "  l2=[] \n",
        "  l1.append(i) \n",
        "  l2 = list(v.split(\",\"))\n",
        "  keepitsafe.update({l1[0]:l2 })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMOkltc1ibxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"qr.txt\") as file:   #finding rel docs with doc number of given file\n",
        "    \n",
        "    n=76\n",
        "    rele={}\n",
        "    rl=[]\n",
        "    count=0\n",
        "    for i in file:\n",
        "        t=i.split()\n",
        "        if int(t[0])==n:\n",
        "            if int(t[-1])==1:\n",
        "                count+=1\n",
        "                rl.append(t[-2])\n",
        "        else:\n",
        "            rele[n]=rl\n",
        "            rl=[]\n",
        "            n+=1\n",
        "            if int(t[-1])==1:\n",
        "                count+=1\n",
        "                rl.append(t[-2])\n",
        "    rele[n]=rl\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iSvcR8hikA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "2c05c90a-3b5e-4e34-e349-940bd4a83b7b"
      },
      "source": [
        "countit={}                          #actual matched documets query wise\n",
        "dict_fin={}\n",
        "temp=76\n",
        "c_r=0\n",
        "print(\"ID : and its relevent docs we have found and true\")\n",
        "for i,v in rele.items():\n",
        "  for i1,v1 in keepitsafe.items():\n",
        "    if(i==i1):\n",
        "      l1=[]\n",
        "      j=str(i)\n",
        "      l1=[value for value in v1 if value in v]\n",
        "      c_r+=len(l1)\n",
        "      x=' '.join([str(elem) for elem in l1])\n",
        "      dict_fin[temp]=l1\n",
        "      temp+=1\n",
        "      print(j+'  '+x)\n",
        "      countit.update({i:len(l1)})"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ID : and its relevent docs we have found and true\n",
            "76  \n",
            "77  1060714_foreign_story_6477224.utf8 1060717_foreign_story_6488684.utf8 1060715_foreign_story_6482002.utf8 1060720_frontpage_story_6501523.utf8 1060716_foreign_story_6485226.utf8 1060727_foreign_story_6531510.utf8 1060804_foreign_story_6567126.utf8\n",
            "78  1041105_nation_story_3968019.utf8\n",
            "79  1070621_nation_story_7952530.utf8\n",
            "80  \n",
            "81  1060822_nation_story_6641118.utf8 1060726_nation_story_6526490.utf8\n",
            "82  1050405_nation_story_4575953.utf8 1050421_frontpage_story_4642066.utf8 1050322_nation_story_4521986.utf8 1070525_nation_story_7825299.utf8 1050331_nation_story_4554929.utf8 1050404_nation_story_4571567.utf8 1050406_nation_story_4578392.utf8 1050417_nation_story_4625341.utf8 1050406_frontpage_story_4580486.utf8 1050422_nation_story_4646055.utf8\n",
            "83  1050219_nation_story_4398037.utf8 1051024_nation_story_5387050.utf8 1050223_nation_story_4411008.utf8 1041022_nation_story_3913967.utf8 1050303_nation_story_4446570.utf8\n",
            "84  \n",
            "85  1051120_frontpage_story_5499247.utf8 1051208_nation_story_5573594.utf8 1060810_nation_story_6591970.utf8 1060614_nation_story_6351073.utf8 1060316_nation_story_5971891.utf8 1051112_frontpage_story_5468138.utf8 1060308_nation_story_5940109.utf8 1060912_nation_story_6732673.utf8 1060929_nation_story_6807710.utf8 1060302_nation_story_5914897.utf8 1051113_nation_story_5471119.utf8 1060106_nation_story_5687738.utf8 1060405_nation_story_6059195.utf8 1051116_frontpage_story_5483063.utf8\n",
            "86  \n",
            "87  \n",
            "88  1041204_nation_story_4084529.utf8 1041118_nation_story_4017603.utf8 1041117_nation_story_4013313.utf8 1050111_frontpage_story_4239312.utf8 1041113_nation_story_3999375.utf8 1041126_nation_story_4051568.utf8 1041119_opinion_story_4019875.utf8 1041115_nation_story_4005216.utf8 1041223_nation_story_4162601.utf8 1041114_frontpage_story_4002703.utf8 1041116_nation_story_4009244.utf8 1041225_nation_story_4171523.utf8\n",
            "89  1051204_frontpage_story_5557422.utf8 1051106_nation_story_5443086.utf8 1051209_frontpage_story_5578676.utf8 1051217_nation_story_5611026.utf8 1051109_nation_story_5454997.utf8 1060617_nation_story_6364334.utf8 1060804_frontpage_story_6566731.utf8 1051107_frontpage_story_5446206.utf8 1060808_nation_story_6583428.utf8\n",
            "90  \n",
            "91  1070629_opinion_story_7987432.utf8 1070624_nation_story_7966280.utf8 1070629_nation_story_7990990.utf8 1070709_opinion_story_8032623.utf8\n",
            "92  1061024_opinion_story_6906965.utf8 1051230_foreign_story_5661567.utf8 1060523_foreign_story_6258616.utf8\n",
            "93  1051214_opinion_story_5595309.utf8 1070424_nation_story_7689072.utf8 1060111_nation_story_5706272.utf8 1051214_nation_story_5598234.utf8 1051224_nation_story_5640236.utf8 1051224_frontpage_story_5640208.utf8\n",
            "94  1061017_nation_story_6879678.utf8\n",
            "95  1070121_nation_story_7290431.utf8 1070310_nation_story_7496881.utf8 1070117_nation_story_7272982.utf8\n",
            "96  1060615_nation_story_6355137.utf8\n",
            "97  1050123_frontpage_story_4287830.utf8 1050114_business_story_4252178.utf8 1050115_business_story_4256685.utf8 1050110_frontpage_story_4235068.utf8 1050504_frontpage_story_4693562.utf8 1050627_business_story_4919496.utf8 1041123_frontpage_story_4038891.utf8 1041127_opinion_story_4054231.utf8 1050117_business_story_4263315.utf8 1041209_frontpage_story_4105660.utf8\n",
            "98  1070526_nation_story_7830524.utf8 1061118_nation_story_7019028.utf8 1061115_nation_story_7003933.utf8\n",
            "99  \n",
            "100  1051115_nation_story_5478696.utf8 1051112_frontpage_story_5468137.utf8 1051112_frontpage_story_5468009.utf8 1051112_nation_story_5468011.utf8 1041107_frontpage_story_3975998.utf8 1051121_nation_story_5502034.utf8 1060118_nation_story_5734651.utf8 1051123_frontpage_story_5511154.utf8 1051123_nation_story_5511465.utf8 1051213_nation_story_5593623.utf8 1050810_nation_story_5095926.utf8 1041110_nation_story_3987208.utf8 1051206_nation_story_5564372.utf8\n",
            "101  1061125_opinion_story_7047966.utf8 1060603_frontpage_story_6305867.utf8 1060603_frontpage_story_6306133.utf8 1060603_nation_story_6305903.utf8 1061121_frontpage_story_7030268.utf8\n",
            "102  1070112_sports_story_7252096.utf8 1061028_sports_story_6927220.utf8 1070224_sports_story_7434948.utf8\n",
            "103  \n",
            "104  1060308_opinion_story_5938184.utf8 1060307_frontpage_story_5936287.utf8 1060311_nation_story_5954497.utf8 1060426_nation_story_6146158.utf8\n",
            "105  1050823_frontpage_story_5145553.utf8 1061128_nation_story_7060323.utf8 1050215_nation_story_4379758.utf8 1070215_nation_story_7395678.utf8 1050315_nation_story_4494613.utf8 1050512_nation_story_4728376.utf8 1070516_nation_story_7784091.utf8 1070523_nation_story_7815243.utf8\n",
            "106  \n",
            "107  1070412_nation_story_7637981.utf8 1070413_nation_story_7642117.utf8 1070407_nation_story_7617227.utf8 1070408_nation_story_7620581.utf8 1070410_nation_story_7628468.utf8\n",
            "108  1050802_opinion_story_5061056.utf8 1050713_opinion_story_4981003.utf8 1061027_frontpage_story_6922474.utf8 1041207_opinion_story_4093295.utf8\n",
            "109  1060402_nation_story_6046366.utf8 1051219_nation_story_5618307.utf8 1060116_nation_story_5725038.utf8 1060103_nation_story_5673645.utf8 1051216_nation_story_5605895.utf8\n",
            "110  1050512_bengal_story_4728585.utf8 1060620_nation_story_6375357.utf8 1050928_nation_story_5293658.utf8 1051227_business_story_5649030.utf8\n",
            "111  1050817_nation_story_5121698.utf8 1050519_nation_story_4757290.utf8 1050413_nation_story_4609077.utf8 1050826_nation_story_5158651.utf8 1050826_frontpage_story_5159316.utf8 1050414_nation_story_4612585.utf8\n",
            "112  \n",
            "113  1061123_foreign_story_7039229.utf8 1061126_foreign_story_7052195.utf8 1061121_foreign_story_7028944.utf8\n",
            "114  1050421_nation_story_4642129.utf8 1050420_frontpage_story_4637476.utf8 1050423_frontpage_story_4651456.utf8\n",
            "115  \n",
            "116  \n",
            "117  \n",
            "118  \n",
            "119  1050609_nation_story_4843677.utf8\n",
            "120  1050210_nation_story_4359510.utf8 1050209_nation_story_4356065.utf8 1050624_nation_story_4908599.utf8\n",
            "121  1070220_nation_story_7414442.utf8\n",
            "122  1070208_nation_story_7365521.utf8 1061205_nation_story_7094715.utf8 1070119_nation_story_7282971.utf8\n",
            "123  1041110_foreign_story_3987311.utf8 1041112_frontpage_story_3995357.utf8 1041112_foreign_story_3995446.utf8 1041208_opinion_story_4086626.utf8 1041112_foreign_story_3995445.utf8 1041106_foreign_story_3972075.utf8 1041113_foreign_story_3999319.utf8 1041112_nation_story_3995294.utf8 1041115_foreign_story_4005520.utf8 1041123_foreign_story_4038063.utf8\n",
            "124  1060612_nation_story_6340989.utf8\n",
            "125  1070521_foreign_story_7806832.utf8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bgExOW2npzH",
        "colab_type": "text"
      },
      "source": [
        "# Finding result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4SYK4noi8IV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de6ae4e0-c330-4810-e70b-5a7a79f235c5"
      },
      "source": [
        "c_r                #no of rel docs"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMEmmhM1i_18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=c_r/653          #recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcXqRzKqj3dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e76a765-a262-4369-b82b-916ecf8c21e7"
      },
      "source": [
        "x"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2679938744257274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIjAW18RjtTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=c_r/500         #precsion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq0axBmlj7Rh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd65f47f-ec15-4def-c67a-c584529c9bed"
      },
      "source": [
        "y"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei7KEJ-MjwaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1=2*(x*y/(x+y))       #f1 score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRCD7WpGkA2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de26c78b-ef0b-4c8a-d107-5b77b296c058"
      },
      "source": [
        "f1"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30355594102341715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTF-FlexkB7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}